{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine learning part 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RGtlRb1HCTrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb99c64-ab45-469d-c840-7efb31237103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import glob\n",
        "import tensorflow.keras.optimizers\n",
        "import os\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, MaxPool2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "TBySPK_vJsnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_characters = {0: 'abraham_grampa_simpson' ,1: 'agnes_skinner' ,2: 'apu_nahasapeemapetilon',\n",
        "          3: 'barney_gumble' ,4: 'bart_simpson' ,5: 'brandine_spuckler',\n",
        "          6: 'carl_carlson' ,7: 'charles_montgomery_burns' ,8: 'chief_wiggum',\n",
        "          9: 'cletus_spuckler' ,10: 'comic_book_guy' ,11: 'disco_stu',\n",
        "          12: 'dolph_starbeam' ,13: 'duff_man' ,14: 'edna_krabappel',\n",
        "          15: 'fat_tony' ,16: 'gary_chalmers' ,17: 'gil',\n",
        "          18: 'groundskeeper_willie' ,19: 'homer_simpson' ,20: 'jimbo_jones',\n",
        "          21: 'kearney_zzyzwicz' ,22: 'kent_brockman',23: 'krusty_the_clown',\n",
        "          24: 'lenny_leonard' ,25: 'lionel_hutz' ,26: 'lisa_simpson',\n",
        "          27: 'lunchlady_doris',28: 'maggie_simpson' ,29: 'marge_simpson',\n",
        "          30: 'martin_prince' ,31: 'mayor_guimby' ,32: 'milhouse_van_houten',\n",
        "          33: 'miss_hoover' ,34: 'moe_szyslak',35: 'ned_flanders',\n",
        "          36: 'nelson_muntz' ,37: 'otto_mann' ,38: 'patty_bouvier',\n",
        "          39: 'principal_skinner' ,40: 'professor_john_frink' ,41: 'rainier_wolfcastle',\n",
        "          42: 'ralph_wiggum' ,43: 'selma_bouvier' ,44: 'sideshow_bob',\n",
        "          45: 'sideshow_mel' ,46: 'snake_jailbird' ,47: 'timothy_lovejoy',\n",
        "          48: 'troy_mcclure' ,49: 'waylon_smithers'}\n",
        "img_width = 60  #圖片大小\n",
        "img_height = 60\n",
        "\n",
        "num_classes = len(dict_characters)  #要識的角色種類\n",
        "test_size = 0.15  # 測試用的百分比\n",
        "imgsPath ='/content/drive/MyDrive/Machine Learning/theSimpsons-train/train'  # 資料匯入"
      ],
      "metadata": {
        "id": "oliLAF_pKgsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.npyio import load\n",
        "def load_pictures():\n",
        "  pics = []\n",
        "  labels = []\n",
        "\n",
        "  for k, v in dict_characters.items():  # k:数字編碼 v:角色Label\n",
        "    # 把某一個角色在檔案夾裡的所有函像檔的路提出来\n",
        "    pictures = [k for k in glob.glob(imgsPath + \"/\" + v + \"/*\")]\n",
        "    print(v + \":\" + str(len(pictures))) #看一下每個角色有多少訓練圖像\n",
        "    for i, pic in enumerate(pictures):\n",
        "      tmp_img = cv2.imread(pic)\n",
        "\n",
        "      #由於OpenCv讀圖像時是以BGR(BLue-Green-Red)我們把他轉至成RGB(Red-Green-Blue\n",
        "      tmp_img =cv2.cvtColor(tmp_img, cv2.COLOR_BGR2RGB)\n",
        "      tmp_img = cv2.resize(tmp_img,(img_height,img_width)) #讓大小一致\n",
        "      pics.append(tmp_img)\n",
        "      labels.append(k)\n",
        "  return np.array(pics), np.array(labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "7HmS_HiBQWTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(save=False, Load=False):\n",
        "  if Load:\n",
        "    # 從檔案系純中載入之前處理保存的訓練資料集與驗證資料集\n",
        "    h5f = h5py.File('trainoe.ns','r')\n",
        "    X_train = h5f['X_train'][:]\n",
        "    X_test = h5f['X_test'][:]\n",
        "    h5f.close()\n",
        "\n",
        "    # 從檔案系統中載入之前處理保存的訓練資料標與驗證資料集\n",
        "    h5f = h5py.File('valid60.hs', 'r')\n",
        "    \n",
        "    y_train = h5f['y_train'][:]\n",
        "    y_test = h5f['y_test '][:]\n",
        "    h5f.close()\n",
        "  else:\n",
        "    #從最原始的圖像檔案開始處理\n",
        "    X , y = load_pictures()\n",
        "    y= keras.utils.np_utils.to_categorical(y,num_classes) # 目標的別款\n",
        "    \n",
        "    #將資料切分為訓練資料集與證資料集(85%vs.15%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    if save:#保存尚未進行一化的图像據\n",
        "      h5f = h5py.File('train60.h5', 'w')\n",
        "      h5f.create_dataset('X_train', data =X_train)\n",
        "      h5f.create_dataset('X_test', data =X_test)\n",
        "      h5f.close()\n",
        "      \n",
        "      h5f = h5py.File('valid60.h5', 'w')\n",
        "      h5f.create_dataset('y_train', data =y_train)\n",
        "      h5f.create_dataset('y_test', data =y_test)\n",
        "      h5f.close()\n",
        "  #進行圖像每個像素值的型別事換與歸一化處理\n",
        "  X_train = X_train.astype('float32')/ 255.\n",
        "  X_test = X_test.astype('float32') / 255.\n",
        "  print(\"Train\", X_train.shape,y_train.shape)\n",
        "  print(\"Valid\", X_test.shape,y_test.shape)\n",
        "  \n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_dataset(save=True, Load=False)"
      ],
      "metadata": {
        "id": "X6iw6cx0TaP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0faa3bce-8d98-4e8c-cdab-74242beb3608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abraham_grampa_simpson:2067\n",
            "agnes_skinner:1866\n",
            "apu_nahasapeemapetilon:2044\n",
            "barney_gumble:1926\n",
            "bart_simpson:2026\n",
            "brandine_spuckler:1878\n",
            "carl_carlson:1897\n",
            "charles_montgomery_burns:2011\n",
            "chief_wiggum:2067\n",
            "cletus_spuckler:1901\n",
            "comic_book_guy:2008\n",
            "disco_stu:1877\n",
            "dolph_starbeam:1863\n",
            "duff_man:1880\n",
            "edna_krabappel:1960\n",
            "fat_tony:1855\n",
            "gary_chalmers:1897\n",
            "gil:1896\n",
            "groundskeeper_willie:1879\n",
            "homer_simpson:2067\n",
            "jimbo_jones:1862\n",
            "kearney_zzyzwicz:1876\n",
            "kent_brockman:2016\n",
            "krusty_the_clown:2023\n",
            "lenny_leonard:1955\n",
            "lionel_hutz:1940\n",
            "lisa_simpson:2039\n",
            "lunchlady_doris:1851\n",
            "maggie_simpson:1914\n",
            "marge_simpson:2025\n",
            "martin_prince:1889\n",
            "mayor_guimby:0\n",
            "milhouse_van_houten:2067\n",
            "miss_hoover:1881\n",
            "moe_szyslak:2035\n",
            "ned_flanders:2034\n",
            "nelson_muntz:1941\n",
            "otto_mann:1857\n",
            "patty_bouvier:1879\n",
            "principal_skinner:2014\n",
            "professor_john_frink:1872\n",
            "rainier_wolfcastle:1905\n",
            "ralph_wiggum:1865\n",
            "selma_bouvier:1880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True)"
      ],
      "metadata": {
        "id": "9yK1rK1HZ4-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_1():\n",
        "  input_shape = (img_height, img_width, 3)\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.5) )\n",
        "  \n",
        "  model.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout (0.5))\n",
        "  model.add(Dense(50, activation=\"softmax\"))\n",
        "\n",
        "  model.compile( optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "model=create_model_1()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3cA7vlXbA87i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel_2():\n",
        "  input_shape = (img_height, img_width, 3)\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), padding='Same',\n",
        "        activation ='relu', input_shape=input_shape, name='conv1'))\n",
        "  model.add(Conv2D(32, kernel_size=(3,3), padding='Same', activation='relu', name='conv2'))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2),name='pool1'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64,kernel_size=(3,3), padding='Same', activation='relu', name='conv3'))\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), padding='Same', activation='relu', name='conv4'))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128,kernel_size=(3,3), padding='Same',activation='relu', name='conv5'))\n",
        "  model.add(Conv2D(128,kernel_size=(3,3), padding='Same', activation='relu', name='conv6'))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2), name='pool2'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dense(50, activation=\"softmax\"))\n",
        "\n",
        "  # Define the optimizer\n",
        "  optimizer = 'Adam'\n",
        "  model.compile(optimizer='Adam',loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "model=createModel_2()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "x-LiamuGBvcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85cb1d0f-2c97-4324-8ff5-97cb5fe2a641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1 (Conv2D)              (None, 60, 60, 32)        896       \n",
            "                                                                 \n",
            " conv2 (Conv2D)              (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " pool1 (MaxPooling2D)        (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv3 (Conv2D)              (None, 30, 30, 64)        18496     \n",
            "                                                                 \n",
            " conv4 (Conv2D)              (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 15, 15, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv5 (Conv2D)              (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " conv6 (Conv2D)              (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              6423552   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                25650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,261,906\n",
            "Trainable params: 7,261,458\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel_3():\n",
        "  pre_trained_res = ResNet50(weights='imagenet', include_top=False,\n",
        "                input_shape=(img_height, img_width, 3))\n",
        "  additional_model = Sequential()\n",
        "  additional_model.add(pre_trained_res)\n",
        "  additional_model.add(Flatten())\n",
        "  additional_model.add(Dense(1024, activation='relu'))\n",
        "  additional_model.add(Dense(512, activation=\"relu\"))\n",
        "  additional_model.add(Dense(50, activation=\"softmax\"))\n",
        "  \n",
        "  # Define the optimizer\n",
        "  optimizer = 'Adam'\n",
        "  additional_model.compile(optimizer='Adam', loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "  return additional_model\n",
        "\n",
        "model = createModel_3()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tvGoeaz2Cip1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509a9db8-50a7-4447-c377-2d538a55e0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 50)                25650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,527,794\n",
            "Trainable params: 32,474,674\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import mod\n",
        "def createModel_4():\n",
        "  model= Sequential()\n",
        "  model.add(VGG16(weights= 'imagenet',\n",
        "        include_top=False,  #不含後三層(辦識層)\n",
        "        input_shape=(img_height,img_width,3)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024,activation=\"relu\",name='full_connect_1'))\n",
        "  model.add(Dense(512, activation=\"relu\",name='full_connect_2'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(50, activation=\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer='Adam', loss= \"categorical_crossentropy\",\n",
        "          metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model = createModel_4()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YNqPHRpWDExz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81673f4d-fd94-45c9-f88a-28093ded94a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " full_connect_1 (Dense)      (None, 1024)              525312    \n",
            "                                                                 \n",
            " full_connect_2 (Dense)      (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 50)                25650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,790,450\n",
            "Trainable params: 15,790,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = createModel_2()\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "# 設定停止函數，當訓練笑過降低到一定程度時，提前停止訓練\n",
        "batch_size = 32  # 單次數量\n",
        "epochs = 50    # 批次數\n",
        "\n",
        "def lr_schedule(epoch):          #停止條件\n",
        "  return lr*(0.1**int(epoch/10))\n",
        "\n",
        "                 "
      ],
      "metadata": {
        "id": "OFqfsQR4D8qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(datagen.flow(X_train, y_train),\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(X_test, y_test),\n",
        "            shuffle=True,\n",
        "            callbacks=[ LearningRateScheduler(lr_schedule),\n",
        "                  ModelCheckpoint('model2.h5', save_best_only=True, period=10),\n",
        "                  EarlyStopping(monitor=\"val_accuracy\" ,patience=3, mode= 'auto')])"
      ],
      "metadata": {
        "id": "HitzniJzEtay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_train_history(history, train_metrics, val_metrics):\n",
        "  plt.plot(history.history.get(train_metrics), '-0',color='r')\n",
        "  plt.plot(history.history.get(val_metrics), '-0',color='b')\n",
        "  plt.ylabel(train_metrics)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend(['train','validation'])\n",
        "  \n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plot_train_history(history, 'loss', 'val_loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plot_train_history(history, 'accuracy', 'val_accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7iDNATDiI9yM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "b3d1f0a6-7a50-4838-f33a-090e3cca93f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a2a6ec3d16fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_train_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_images(path):   # 讀取要測試的資料\n",
        "  images=[]\n",
        "  for i in range(10791):\n",
        "    image=cv2.resize(cv2.imread(path+ str(i+1)+ '.jpg') ,(img_height,img_width))\n",
        "    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 轉換成RGB\n",
        "    images.append(image)\n",
        "  images=np.array(images,dtype=np.float32)/255\n",
        "  return images\n",
        "\n",
        "model = load_model('model2.h5') # 載入模型\n",
        "imgsPath ='/content/drive/MyDrive/Machine Learning/theSimpsons-test/test/'\n",
        "read_test_images = read_images(imgsPath)\n",
        "predict = model.predict(read_test_images) # 開始預測\n",
        "predict = np.argmax(predict, axis=1)"
      ],
      "metadata": {
        "id": "U6Zc_BCrLn3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('predict2.csv', 'w') as f :  # 存檔成csv，並依照題目要求填入\n",
        "  f.write('id,character\\n')\n",
        "  for i in range(len(predict)):\n",
        "    f.write(str(i+1)+ ',' + dict_characters[(predict[i])] + '\\n')"
      ],
      "metadata": {
        "id": "cZ48RvWDPmP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#使用sklearn的分類報告來看預測結果\n",
        "  \n",
        "print('\\n',sklearn.metrics.classification_report(true,\n",
        "                        predict,\n",
        "                        target_names=list(dict_characters.values())), sep='')"
      ],
      "metadata": {
        "id": "77s_xGVnKiGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}